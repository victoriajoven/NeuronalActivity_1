{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5317a8",
   "metadata": {},
   "source": [
    "## Loading preprocessed data\n",
    "Loading preprocessed data in part 1 about car features and CO2 pollution prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af7ca289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Loading preprocessed data\n",
    "\n",
    "\n",
    "base_path = Path(os.path.abspath(\"03_model_comparison.ipynb\")).parent.parent\n",
    "X_train = np.load(base_path / \"data/processed/X_train_preprocessed.npy\")\n",
    "X_test  = np.load(base_path / \"data/processed/X_test_preprocessed.npy\")\n",
    "y_train = np.load(base_path / \"data/learn/y_train.npy\")\n",
    "y_test  = np.load(base_path / \"data/check/y_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a766a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "X_train: (800, 23)\n",
      "X_test : (200, 23)\n",
      "y_train: (800,)\n",
      "y_test : (200,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test :\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adc470d",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0483ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Activation Functions\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    # x is the ACTIVATION, not the field\n",
    "    return x * (1 - x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6fd7e",
   "metadata": {},
   "source": [
    "## MULTILAYER WITH BACKPROPAGATION + MOMENTUM\n",
    "The techniques of BACKPROPAGATION and MOMENTUM are combined:\n",
    "- Backpropagation calculates the current gradient to indicate in which direction the weight should move to reduce the error.\n",
    "- Momentum reviews the previous update(with self.d_w_prev and self.d_theta_prev )\n",
    "- Finally are combined with the add in:\n",
    "    d_w[i, j] = (...GRADIENTE and MOMENTUM)\n",
    "        and\n",
    "    d_theta[i] = (...GRADIENTE and MOMENTUM)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b76e6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer:\n",
    "    def __init__(self, n, eta=0.01, alpha=0.5):\n",
    "        \"\"\"\n",
    "        n: lista con neuronas por capa (ej: [4, 6, 1])\n",
    "        eta: learning rate\n",
    "        alpha: momentum\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.L = len(n)\n",
    "        self.eta = eta\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Fixed activation = sigmoid\n",
    "        self.f = sigmoid\n",
    "        self.df = d_sigmoid\n",
    "\n",
    "        # Fields, activations, and deltas\n",
    "        self.h = [np.zeros(n[l]) for l in range(self.L)]\n",
    "        self.xi = [np.zeros(n[l]) for l in range(self.L)]\n",
    "        self.delta = [np.zeros(n[l]) for l in range(self.L)]\n",
    "\n",
    "        # Weights and thresholds\n",
    "        self.w = [None]\n",
    "        self.theta = [None]\n",
    "\n",
    "        for l in range(1, self.L):\n",
    "            self.w.append(np.random.randn(n[l], n[l-1]) * 0.1)\n",
    "            self.theta.append(np.random.randn(n[l]) * 0.1)\n",
    "\n",
    "        # Momentum\n",
    "        self.d_w_prev = [None] + [np.zeros_like(self.w[l]) for l in range(1, self.L)]\n",
    "        self.d_theta_prev = [None] + [np.zeros_like(self.theta[l]) for l in range(1, self.L)]\n",
    "\n",
    "\n",
    "    # FEED-FORWARD, added to multilayer review document G\n",
    "    def feed_forward(self, x):\n",
    "        self.xi[0] = x\n",
    "\n",
    "        for l in range(1, self.L):\n",
    "            self.h[l] = self.w[l] @ self.xi[l-1] - self.theta[l]\n",
    "            self.xi[l] = self.f(self.h[l])\n",
    "\n",
    "        return self.xi[-1]\n",
    "\n",
    "\n",
    "    # BACKPROPAGATION,, added to multilayer review document G\n",
    "    def backprop(self, target):\n",
    "        # Salida (ecuación 11)\n",
    "        self.delta[-1] = self.df(self.xi[-1]) * (self.xi[-1] - target)\n",
    "\n",
    "        # Hidden layers\n",
    "        for l in range(self.L-2, 0, -1):\n",
    "            self.delta[l] = self.df(self.xi[l]) * (self.w[l+1].T @ self.delta[l+1])\n",
    "\n",
    "\n",
    "    # WEIGHT UPDATE, by requiment in document \n",
    "    def update(self):\n",
    "\n",
    "     for l in range(1, self.L):\n",
    "\n",
    "        # d_w have the same form that w[l]: (n[l], n[l-1])\n",
    "        d_w = np.zeros_like(self.w[l])\n",
    "        d_theta = np.zeros_like(self.theta[l])\n",
    "\n",
    "        \n",
    "        # UPDATE WEIGHT BY WEIGHT\n",
    "        \n",
    "        for i in range(self.n[l]):          # destination neuron in layer l\n",
    "            for j in range(self.n[l-1]):    # origin neuron in layer l-1\n",
    "\n",
    "                # formula as in the example of weights in the statement\n",
    "                d_w[i, j] = (\n",
    "                    -self.eta * self.delta[l][i] * self.xi[l-1][j]\n",
    "                    + self.alpha * self.d_w_prev[l][i, j]\n",
    "                )\n",
    "\n",
    "        \n",
    "        # Threshold update\n",
    "        \n",
    "        for i in range(self.n[l]):\n",
    "            d_theta[i] = (\n",
    "                self.eta * self.delta[l][i]\n",
    "                + self.alpha * self.d_theta_prev[l][i]\n",
    "            )\n",
    "\n",
    "        \n",
    "        # APPLY UPDATES\n",
    "        self.w[l] += d_w\n",
    "        self.theta[l] += d_theta\n",
    "\n",
    "        # Save changes\n",
    "        self.d_w_prev[l] = d_w\n",
    "        self.d_theta_prev[l] = d_theta\n",
    "\n",
    "\n",
    "\n",
    "    # Training\n",
    "    def train(self, X, y, epochs=2000):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # online training (patrón a patrón)\n",
    "            for i in range(len(X)):\n",
    "                self.feed_forward(X[i])\n",
    "                self.backprop(y[i])\n",
    "                self.update()\n",
    "\n",
    "            # Show partial error\n",
    "            if epoch % 200 == 0:\n",
    "                print(\"Epoch\", epoch, \"Error:\", self.error(X, y))\n",
    "\n",
    "\n",
    "    # Calculate error\n",
    "    def error(self, X, y):\n",
    "        E = 0\n",
    "        for i in range(len(X)):\n",
    "            pred = self.feed_forward(X[i])\n",
    "            E += np.sum((pred - y[i])**2)\n",
    "        return E / 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108bc38",
   "metadata": {},
   "source": [
    "## CREATE AND TRAIN THE NEURAL NETWORK\n",
    "I have been adjusting the dynamic values to try to achieve a model with more optimal learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48f8a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Error: 6249067.969317463\n",
      "Epoch 200 Error: 6249067.004708339\n",
      "Epoch 400 Error: 6249066.981870297\n",
      "Epoch 600 Error: 6248928.531752168\n",
      "Epoch 800 Error: 6248928.515526523\n",
      "Epoch 1000 Error: 6248928.511036392\n",
      "Epoch 1200 Error: 6248928.508940865\n",
      "Epoch 1400 Error: 6248928.507729924\n",
      "Epoch 1600 Error: 6248928.506941907\n",
      "Epoch 1800 Error: 6248928.506388568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CREATE AND TRAIN THE NEURAL NETWORK\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "\n",
    "ml = Multilayer(\n",
    "    n=[n_input, 12, 1],  \n",
    "    eta=0.07,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "ml.train(X_train, y_train, epochs=2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb90501",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02bf81e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE in test: 16978.81186703673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Evaluation\n",
    "predictions = np.array([ml.feed_forward(x) for x in X_test]).flatten()\n",
    "mse = np.mean((predictions - y_test.flatten())**2)\n",
    "\n",
    "print(\"\\nMSE in test:\", mse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca50108",
   "metadata": {},
   "source": [
    "## PREDICTION EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1154b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CO2 Prediction (normalized): [0.00382502]\n",
      "Real value (normalized): 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nuevo = X_test[0]  # any vector already preprocessed\n",
    "pred = ml.feed_forward(nuevo)\n",
    "\n",
    "print(\"\\nCO2 Prediction (normalized):\", pred)\n",
    "print(\"Real value (normalized):\", y_test[0])\n",
    "#NeuralNet is added with the training percentage as an input value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043d0ed",
   "metadata": {},
   "source": [
    "## NeuralNet\n",
    "NeuralNet is added with the training percentage as an input value. In this case with 80% training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32b8880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, X, y, percentage, layers=[6], eta=0.05, alpha=0.5):\n",
    "        \"\"\"\n",
    "        percentage: percentage of data used for TRAINING.\n",
    "                    if percentage = 0 is the 100% training.\n",
    "                    We will use percentage=0.8 for 80% training.\n",
    "        \"\"\"\n",
    "\n",
    "        if percentage == 0.8:\n",
    "            # TODO training\n",
    "            self.X_train = X\n",
    "            self.y_train = y\n",
    "            self.X_val = None\n",
    "            self.y_val = None\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if percentage > 1:\n",
    "                p = percentage / 100.0\n",
    "            else:\n",
    "                p = percentage\n",
    "\n",
    "            N = len(X)\n",
    "            N_train = int(N * p)\n",
    "\n",
    "            self.X_train = X[:N_train]\n",
    "            self.y_train = y[:N_train]\n",
    "            self.X_val  = X[N_train:]\n",
    "            self.y_val  = y[N_train:]\n",
    "\n",
    "        # Dynamic architecture according to input/output dimensions\n",
    "        n_input = X.shape[1]\n",
    "        n_output = y.shape[1]\n",
    "        architecture = [n_input] + layers + [n_output]\n",
    "\n",
    "        self.mlp = Multilayer(\n",
    "            n=architecture,\n",
    "            eta=eta,\n",
    "            alpha=alpha\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece401a",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The BP model is not suitable for predicting CO2. The reason is : despite increasing the number of neurons to 12, the training is not optimal because learning stagnates after epoch 600 and The test MSE is very high(the error reduction is minimal 6249067.97−6248928.50 aprox 139.5), which indicates poor generalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
